{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_Mar__8_18:36:24_Pacific_Standard_Time_2022\n",
      "Cuda compilation tools, release 11.6, V11.6.124\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\n",
      "torch:  1.13 ; cuda:  1.13.0\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-t', '--task')\n",
    "parser.add_argument('--gpu')\n",
    "args = argparse.Namespace(\n",
    "    gpu = None,\n",
    "    task = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json, cv2, random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = args.task\n",
    "root_dir = 'C:/Users/wlaud/OneDrive - 아주대학교/PythonWorkspace/가축 발정탐지 행동식별 AI 모델'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keypoint_names = {\n",
    "    'cow': list(map(int, range(13))),\n",
    "    'pig': list(map(int, range(8)))\n",
    "}\n",
    "\n",
    "keypoint_flip_map = {\n",
    "    'cow': [('5', '7'), ('6', '8'), ('9', '11'), ('10', '12')],\n",
    "    'pig': [('2', '3'), ('4','5'), ('6', '7')],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cow': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
       " 'pig': [0, 1, 2, 3, 4, 5, 6, 7]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_to_id = {\n",
    "    'cow': {\n",
    "        'eating': 0,\n",
    "        'standing': 1,\n",
    "        'lying': 2,\n",
    "        'sitting': 3,\n",
    "        'tailing': 4,\n",
    "        'head shaking': 5,\n",
    "    },\n",
    "    \n",
    "    'pig': {\n",
    "        'eating': 0,\n",
    "        'standing': 1,\n",
    "        'lying': 2,\n",
    "        'sitting': 3,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from detectron2.structures import BoxMode\n",
    "\n",
    "def get_dataset_dicts(root_dir, task, d):\n",
    "    assert task in ['pig', 'cow']\n",
    "    assert d in ['train', 'val']\n",
    "    json_files = sorted(glob(os.path.join(root_dir, task, '%s_train_json'%task, '*.json')))\n",
    "\n",
    "    if d == 'train':\n",
    "        json_files = json_files[int(len(json_files) * 0.05) :]\n",
    "    else:\n",
    "        json_files = json_files[:int(len(json_files) * 0.05)]\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, json_path in enumerate(json_files):\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                anns = json.load(f)\n",
    "            \n",
    "            idx = int(idx)\n",
    "            record = {}\n",
    "\n",
    "            filename = json_path.replace('_json', '_image').replace('.json', '.jpg')\n",
    "            height, width = anns['IMAGE']['HEIGHT'], anns['IMAGE']['WIDTH']\n",
    "\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = idx\n",
    "            record[\"height\"] = height\n",
    "            record[\"width\"] = width\n",
    "                \n",
    "            objs = []\n",
    "            for obj_info in anns['ANNOTATION_INFO']:\n",
    "                category_id = class_to_id[task][obj_info['ACTION_NAME']]\n",
    "                keypoints = obj_info['KEYPOINTS']\n",
    "                \n",
    "                x_min, x_max = min(keypoints[::3]), max(keypoints[::3])\n",
    "                y_min, y_max = min(keypoints[1::3]), max(keypoints[1::3])\n",
    "\n",
    "                x_min -= 30\n",
    "                x_max += 30\n",
    "                y_max += 30\n",
    "                if task == 'pig':\n",
    "                    y_min -= 200\n",
    "                else:\n",
    "                    y_min -= 30\n",
    "                \n",
    "                objs.append({\n",
    "                    \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"keypoints\": obj_info['KEYPOINTS'],\n",
    "                    \"category_id\": category_id\n",
    "                })\n",
    "\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(filename, e)\n",
    "            \n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8868\\887936858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mDatasetCatalog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset_%s_%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_dataset_dicts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     MetadataCatalog.get(\"dataset_%s_%s\" % (task, d)).set(thing_classes=list(class_to_id[task].keys()),\n\u001b[0m\u001b[0;32m      4\u001b[0m                                             \u001b[0mkeypoint_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeypoint_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                             keypoint_flip_map=keypoint_flip_map[task])\n",
      "\u001b[1;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "for d in [\"train\", \"val\"]:\n",
    "    DatasetCatalog.register(\"dataset_%s_%s\" % (task, d), lambda d=d: get_dataset_dicts(root_dir, task, d))\n",
    "    MetadataCatalog.get(\"dataset_%s_%s\" % (task, d)).set(thing_classes=list(class_to_id[task].keys()),\n",
    "                                            keypoint_names=keypoint_names[task],\n",
    "                                            keypoint_flip_map=keypoint_flip_map[task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"dataset_%s_train\" % task,)\n",
    "cfg.DATASETS.TEST = (\"dataset_%s_val\" % task,)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 2000\n",
    "cfg.SOLVER.BASE_LR = 0.005  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 100000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = [60000,80000]        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(list(class_to_id[task].keys()))  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_KEYPOINTS = len(keypoint_names[task])  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.OUTPUT_DIR = 'output_%s' % task\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67a67815f561936a237b330b4d705eb5c369a6c9583a9b9730f874040d906ccb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
